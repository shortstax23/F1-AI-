{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename_info(df, filename):\n",
    "    # Extract the base name (in case a full path is passed)\n",
    "    base = os.path.basename(filename)\n",
    "    \n",
    "    # Regex to get race name and year\n",
    "    match = re.match(r\"f1_data_(.+)_([0-9]{4})\\.csv\", base)\n",
    "    \n",
    "    if match:\n",
    "        race_name = match.group(1).replace(\"_\", \" \")  # Turn underscores into spaces\n",
    "        year = int(match.group(2))\n",
    "        \n",
    "        df[\"RaceName\"] = race_name\n",
    "        df[\"Year\"] = year\n",
    "    else:\n",
    "        print(\"⚠️ Filename doesn't match expected pattern.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_practice_sessions(df):\n",
    "    sessions = [\"FP1\", \"FP2\", \"FP3\"]\n",
    "    penalty_seconds = 0.5\n",
    "\n",
    "    # Initialize imputation flags explicitly\n",
    "    for session in sessions:\n",
    "        df[f\"IsImputed_{session}\"] = False\n",
    "\n",
    "    # Loop through each session\n",
    "    for session in sessions:\n",
    "        lap_col = f\"LapTime_{session}\"\n",
    "        \n",
    "        # Drivers missing practice lap data for this session\n",
    "        missing_drivers = df[df[lap_col].isna()]\n",
    "\n",
    "        for idx, driver_row in missing_drivers.iterrows():\n",
    "            team, race, year, driver = driver_row[\"TeamName\"], driver_row[\"RaceName\"], driver_row[\"Year\"], driver_row[\"Driver\"]\n",
    "\n",
    "            # Teammate data\n",
    "            teammate = df[\n",
    "                (df[\"TeamName\"] == team) &\n",
    "                (df[\"RaceName\"] == race) &\n",
    "                (df[\"Year\"] == year) &\n",
    "                (df[\"Driver\"] != driver) &\n",
    "                (~df[lap_col].isna())\n",
    "            ]\n",
    "\n",
    "            if teammate.empty:\n",
    "                print(f\"⚠️ No teammate data for {driver} in {session} at {race} ({year}). Consider removing this row manually.\")\n",
    "                continue  # Skip if no teammate data available\n",
    "\n",
    "            teammate_row = teammate.iloc[0]\n",
    "\n",
    "            # Get all columns for this practice session\n",
    "            session_cols = [col for col in df.columns if f\"_{session}\" in col]\n",
    "\n",
    "            # Copy teammate's data for entire session\n",
    "            df.loc[idx, session_cols] = teammate_row[session_cols].values\n",
    "\n",
    "            # Penalize LapTime explicitly\n",
    "            df.at[idx, lap_col] += penalty_seconds\n",
    "\n",
    "            # Mark as imputed\n",
    "            df.at[idx, f\"IsImputed_{session}\"] = True\n",
    "\n",
    "            # Recalculate FastestPracticeTime clearly after imputation\n",
    "            df.at[idx, \"FastestPracticeTime\"] = df.loc[idx, [\"LapTime_FP1\", \"LapTime_FP2\", \"LapTime_FP3\"]].min()\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_race_data(csv_path, output_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    process_filename_info(df, csv_path)\n",
    "    \n",
    "    # Check if 'TotalRaceTime' column exists before dropping\n",
    "    if 'TotalRaceTime' in df.columns:\n",
    "        df = df.dropna(subset=[\"TotalRaceTime\"])\n",
    "    else:\n",
    "        print(f\"⚠️ Column 'TotalRaceTime' missing in {csv_path}. Skipping file.\")\n",
    "        return  # skip further processing for this file\n",
    "\n",
    "    # Convert all relevant time columns to seconds\n",
    "    time_cols = [\n",
    "        \"LapTime_FP1\", \"LapTime_FP2\", \"LapTime_FP3\",\n",
    "        \"AvgLapTime_LongestStint_FP1\", \"AvgLapTime_LongestStint_FP2\", \"AvgLapTime_LongestStint_FP3\",\n",
    "        \"Delta_FirstLastLap_FP1\", \"Delta_FirstLastLap_FP2\", \"Delta_FirstLastLap_FP3\",\n",
    "        \"Q1_FastestLap\", \"Q2_FastestLap\", \"Q3_FastestLap\"\n",
    "    ]\n",
    "    for col in time_cols:\n",
    "        df[col] = pd.to_timedelta(df[col]).dt.total_seconds()\n",
    "\n",
    "    # Fastest laps\n",
    "    df[\"FastestPracticeTime\"] = df[[\"LapTime_FP1\", \"LapTime_FP2\", \"LapTime_FP3\"]].min(axis=1)\n",
    "    df[\"FastestQualifyingTime\"] = df[[\"Q1_FastestLap\", \"Q2_FastestLap\", \"Q3_FastestLap\"]].min(axis=1)\n",
    "\n",
    "    # Map compounds to categorical\n",
    "    compounds = {\"SOFT\": 0, \"MEDIUM\": 1, \"HARD\": 2, \"INTERMEDIATE\": 3, \"WET\": 4}\n",
    "\n",
    "    # Find compound of fastest FP lap\n",
    "    conditions = [\n",
    "        df[\"LapTime_FP1\"] == df[\"FastestPracticeTime\"],\n",
    "        df[\"LapTime_FP2\"] == df[\"FastestPracticeTime\"],\n",
    "        df[\"LapTime_FP3\"] == df[\"FastestPracticeTime\"]\n",
    "    ]\n",
    "    choices = [df[\"Compound_FP1\"], df[\"Compound_FP2\"], df[\"Compound_FP3\"]]\n",
    "    df[\"FastestPracticeCompound\"] = np.select(conditions, choices, default=np.nan)\n",
    "    \n",
    "    # Map compounds\n",
    "    compound_cols = [\"FastestPracticeCompound\", \"LongestStintCompound_FP1\", \"LongestStintCompound_FP2\", \"LongestStintCompound_FP3\",\n",
    "                    \"Compound_FP1\", \"Compound_FP2\", \"Compound_FP3\",\n",
    "                     ]\n",
    "    for col in compound_cols:\n",
    "        df[col] = df[col].map(compounds)\n",
    "\n",
    "\n",
    "    # Normalize all speed trap data vs. session slowest\n",
    "    speed_cols = [\n",
    "        \"SpeedST_FP1\", \"SpeedFL_FP1\", \"SpeedI1_FP1\", \"SpeedI2_FP1\",\n",
    "        \"SpeedST_FP2\", \"SpeedFL_FP2\", \"SpeedI1_FP2\", \"SpeedI2_FP2\",\n",
    "        \"SpeedST_FP3\", \"SpeedFL_FP3\", \"SpeedI1_FP3\", \"SpeedI2_FP3\",\n",
    "        \"Q1_TopSpeedST\", \"Q2_TopSpeedST\", \"Q3_TopSpeedST\"\n",
    "    ]\n",
    "\n",
    "    for col in speed_cols:\n",
    "        df[col] = df[col] - df[col].min()\n",
    "\n",
    "\n",
    "    # Normalize race time\n",
    "    df[\"TotalRaceTime\"] = pd.to_timedelta(df[\"TotalRaceTime\"]).dt.total_seconds()\n",
    "    totalTimeFirst = df[\"TotalRaceTime\"].max()\n",
    "    df[\"TotalRaceTime\"] = df[\"TotalRaceTime\"].fillna(totalTimeFirst)\n",
    "    df.loc[df[\"TotalRaceTime\"] != totalTimeFirst, \"TotalRaceTime\"] += totalTimeFirst\n",
    "\n",
    "    df = impute_missing_practice_sessions(df)\n",
    "\n",
    "    # Append to combined CSV (create it if doesn't exist)\n",
    "    if not os.path.exists(output_path):\n",
    "        df.to_csv(output_path, index=False)\n",
    "    else:\n",
    "        df.to_csv(output_path, mode='a', index=False, header=False)  # Append without writing header again\n",
    "\n",
    "    print(f\"Processed and saved: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder path (relative to script location)\n",
    "#data_folder = './data'\n",
    "\n",
    "## Get all CSV files in the folder\n",
    "#csv_files = glob.glob(os.path.join(data_folder, '*.csv'))\n",
    "\n",
    "## Loop through each CSV\n",
    "#for csv_file in csv_files:\n",
    "#    process_race_data(csv_file, \"dataset/f1_data_combined.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: data/f1_data_Saudi_Arabian_Grand_Prix_2025.csv\n"
     ]
    }
   ],
   "source": [
    "process_race_data(\"data/f1_data_Saudi_Arabian_Grand_Prix_2025.csv\", \"dataset/f1_data_combined.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
