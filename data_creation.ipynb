{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import fastf1\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable cache to locally store data, so that when load data don't need to take them every time from the api \n",
    "cache_dir = os.path.expanduser('~/fastf1_cache')\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "fastf1.Cache.enable_cache(cache_dir)\n",
    "\n",
    "# I don't know if this is needed considering what we are doing now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_append_event(year, event_name, \n",
    "                           session_types=[\"FP1\", \"FP2\", \"FP3\", \"Q\", \"R\"], \n",
    "                           csv_path=\"data/f1_laps.csv\"):\n",
    "    df_list = []\n",
    "    \n",
    "    # Fetch sessions for the specified event\n",
    "    for session_type in session_types:\n",
    "        try:\n",
    "            session = fastf1.get_session(year, event_name, session_type)\n",
    "            session.load(laps=True)\n",
    "            laps = session.laps.copy()\n",
    "            results = session.results.copy()\n",
    "\n",
    "            # Add some columns to keep track of the event\n",
    "            \n",
    "            laps[\"Session\"] = session_type\n",
    "            laps[\"Year\"] = year\n",
    "            laps[\"Round\"] = session.event.RoundNumber\n",
    "            laps[\"EventName\"] = session.event.EventName\n",
    "\n",
    "            df_list.append(laps)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {year} - {event_name} - {session_type} due to error: {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        # No data collected, so just return without writing anything\n",
    "        return\n",
    "\n",
    "    # Combine all laps for this event\n",
    "    event_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Check if the CSV file already exists in your data folder\n",
    "    if not os.path.exists(csv_path):\n",
    "        # If the file doesn't exist, create a new one (header included)\n",
    "        event_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Created new CSV at {csv_path} with data for {event_name} {year}.\")\n",
    "    else:\n",
    "        # If the file does exist, append data (no header this time)\n",
    "        event_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "        print(f\"Appended data for {event_name} {year} to existing CSV at {csv_path}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Australian Grand Prix - Practice 1 [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '5', '6', '7', '10', '12', '14', '16', '18', '22', '23', '27', '30', '31', '44', '55', '63', '81', '87']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Practice 2 [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tNo lap data for driver 87\n",
      "core        WARNING \tFailed to perform lap accuracy check - all laps marked as inaccurate (driver 87)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '5', '6', '7', '10', '12', '14', '16', '18', '22', '23', '27', '30', '31', '44', '55', '63', '81', '87']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Practice 3 [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '5', '6', '7', '10', '12', '14', '16', '18', '22', '23', '27', '30', '31', '44', '55', '63', '81', '87']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Qualifying [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '1', '63', '22', '23', '16', '44', '10', '55', '6', '14', '18', '7', '5', '12', '27', '30', '31', '87']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Race [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 4 completed the race distance 00:00.022000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '63', '12', '23', '18', '27', '16', '81', '44', '10', '22', '31', '87', '30', '5', '14', '55', '7', '6']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Practice 1 [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new CSV at data/f1_laps.csv with data for Australian Grand Prix 2025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '5', '6', '7', '10', '12', '14', '16', '18', '22', '23', '27', '30', '31', '44', '55', '63', '81', '87']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Sprint Qualifying [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "core        WARNING \tSprint Qualifying is not supported by Ergast! Limited results are calculated from timing data.\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '1', '81', '16', '63', '4', '12', '22', '23', '18', '14', '87', '55', '5', '6', '7', '10', '31', '27', '30']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Qualifying [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 2025 - Chinese Grand Prix - SR due to error: Invalid session type 'SR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '63', '4', '1', '44', '16', '6', '12', '22', '23', '31', '27', '14', '18', '55', '10', '87', '7', '5', '30']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Race [v3.5.3]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '63', '1', '31', '12', '23', '87', '18', '55', '6', '30', '7', '5', '27', '22', '14', '16', '44', '10']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended data for Chinese Grand Prix 2025 to existing CSV at data/f1_laps.csv.\n"
     ]
    }
   ],
   "source": [
    "# add 2025 events until now \n",
    "fetch_and_append_event(2025, \"Australian Grand Prix\")\n",
    "fetch_and_append_event(2025, \"Chinese Grand Prix\", session_types=[\"FP1\", \"SQ\", \"SR\",  \"Q\", \"R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider doing some work on data before actually appending it to the csv -> take from 3 practice session the fastest lap, \n",
    "# try to estimate the average time during a stint in practice \n",
    "# also add to dataset the Results data -> using SessionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_append_event(year, event_name, \n",
    "                           session_types=[\"FP1\", \"FP2\", \"FP3\", \"Q\", \"R\"], \n",
    "                           csv_path=\"data/f1_laps.csv\"):\n",
    "    df_list = []\n",
    "    \n",
    "    # load data for all sessions \n",
    "    fp1_session = fastf1.get_session(year, event_name, \"FP1\")\n",
    "    fp1_session.load(laps=True)\n",
    "    fp1_laps = fp1_session.laps.copy()\n",
    "    fp1_results = fp1_session.results.copy()\n",
    "    fp1_laps[\"Session\"] = \"FP1\"\n",
    "\n",
    "    fp1 = fp1_results.copy()\n",
    "    # get fastest lap for each driver in the session \n",
    "    fastest_laps = fp1_laps[fp1_laps[\"IsPersonalBest\"] == True]\n",
    "    # get average lap time for best stint of each driver -> include also variation between first and last lap and number of laps of the stint (maybe better consider stint with more laps)\n",
    "    \n",
    "    # merge all in one single dataframe \n",
    "    fp1 = fp1.merge(fastest_laps, on=\"Driver\", how=\"left\", suffixes=(\"\", \"_Fastest\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fp2_session = fastf1.get_session(year, event_name, \"FP2\")\n",
    "    fp2_session.load(laps=True)\n",
    "    fp2_laps = fp2_session.laps.copy()\n",
    "    fp2_results = fp2_session.results.copy()\n",
    "\n",
    "    fp3_session = fastf1.get_session(year, event_name, \"FP3\")\n",
    "    fp3_session.load(laps=True)\n",
    "    fp3_laps = fp3_session.laps.copy()\n",
    "    fp3_results = fp3_session.results.copy()\n",
    "\n",
    "    quali_session = fastf1.get_session(year, event_name, \"Q\")\n",
    "    quali_session.load(laps=True)\n",
    "    quali_laps = quali_session.laps.copy()\n",
    "    quali_results = quali_session.results.copy()\n",
    "\n",
    "    race_session = fastf1.get_session(year, event_name, \"R\")\n",
    "    race_session.load(laps=True)\n",
    "    race_results = race_session.results.copy()\n",
    "\n",
    "\n",
    "\n",
    "    # Fetch sessions for the specified event\n",
    "    for session_type in session_types:\n",
    "        try:\n",
    "            session = fastf1.get_session(year, event_name, session_type)\n",
    "            session.load(laps=True)\n",
    "            laps = session.laps.copy()\n",
    "            results = session.results.copy()\n",
    "\n",
    "            # Add some columns to keep track of the event\n",
    "            \n",
    "            laps[\"Session\"] = session_type\n",
    "            laps[\"Year\"] = year\n",
    "            laps[\"Round\"] = session.event.RoundNumber\n",
    "            laps[\"EventName\"] = session.event.EventName\n",
    "\n",
    "            df_list.append(laps)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {year} - {event_name} - {session_type} due to error: {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        # No data collected, so just return without writing anything\n",
    "        return\n",
    "\n",
    "    # Combine all laps for this event\n",
    "    event_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Check if the CSV file already exists in your data folder\n",
    "    if not os.path.exists(csv_path):\n",
    "        # If the file doesn't exist, create a new one (header included)\n",
    "        event_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Created new CSV at {csv_path} with data for {event_name} {year}.\")\n",
    "    else:\n",
    "        # If the file does exist, append data (no header this time)\n",
    "        event_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "        print(f\"Appended data for {event_name} {year} to existing CSV at {csv_path}.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
